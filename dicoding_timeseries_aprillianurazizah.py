# -*- coding: utf-8 -*-
"""Dicoding_TimeSeries_AprilliaNurAzizah.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NQ41ylMrfXEG4dqdiok_Yj8Hq-BwejpT

###Nama      : Aprillia Nur Azizah 
###Unsername : aprillianuraz
###Email     : aprilliaazizah3@gmail.com
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn import preprocessing

df = pd.read_csv('/content/drive/MyDrive/Dicoding/Dataset/DailyDelhiClimate.csv', parse_dates=['date'], index_col='date')
df.head()

df.info()

#Cek Missing Value
df.isnull().sum()

df['hour'] = df.index.hour
df['day_of_week'] = df.index.dayofweek
df['day_of_month'] = df.index.day
df['month'] = df.index.month
df.head()

#Grafik meantemp setiap bulan 
data_by_month = df.resample('M').sum()
time = data_by_month.index.values
temp = data_by_month['meantemp'].values
plt.figure(figsize=(15,5))
plt.plot(time, temp)
plt.title('Temperature average',
          fontsize=20);

train_size = int(len(df) * 0.8) # train dataset 80%
train, val = df.iloc[0:train_size], df.iloc[train_size:len(df)]#validation 20%

print(train.shape, val.shape)

#normalization 
transformer = RobustScaler()
temp_transformer = transformer.fit(train[['meantemp']])
train['meantemp'] = temp_transformer.transform(train[['meantemp']])
val['meantemp'] = temp_transformer.transform(val[['meantemp']])

scaler = preprocessing.MinMaxScaler()
temp_scaler = scaler.fit(train[['meantemp']])
train['meantemp'] = temp_scaler.transform(train[['meantemp']])
val['meantemp'] = temp_scaler.transform(val[['meantemp']])

scale_col = ['humidity', 'wind_speed', 'meanpressure']
scale_transformer = transformer.fit(train[scale_col].to_numpy())
train.loc[:, scale_col] = scale_transformer.transform(
    train[scale_col].to_numpy()
)

val.loc[:, scale_col] = scale_transformer.transform(
    val[scale_col].to_numpy()
)

steps = 20
def createDataset(X, y, steps):
    Xs, ys = [], []
    for i in range(len(X) - steps):
        data = X.iloc[i:(i + steps)].values
        Xs.append(data)        
        ys.append(y.iloc[i + steps])
        
    return np.array(Xs), np.array(ys)

x_train, y_train = createDataset(train, train.meantemp, steps)
x_val, y_val = createDataset(val, val.meantemp, steps)
print(x_train.shape, y_train.shape)

model = tf.keras.models.Sequential([
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

class my_allback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('mae') < 0.1):
            print("MAE < 10%")
            self.model.stop_training = True

    def on_train_end(self, epoch, logs={}):
        print('Done')

callbacks = my_allback()

history = model.fit(x_train,
                    y_train,
                    epochs=100,
                    steps_per_epoch = 50,
                    batch_size=32,
                    validation_split=0.2,
                    shuffle=False,
                    callbacks = callbacks)

#MAE Plot
accry = history.history['mae']
validation_accry = history.history['val_mae']
plt.plot(accry, 'g', label='Training MAE')
plt.plot(validation_accry , 'b', label='Validation MAE')
plt.title('Training and Validation MAE')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

#Loss Plot
loss = history.history['loss']
validation_loss = history.history['val_loss']
plt.plot(loss, 'g', label='Training loss')
plt.plot(validation_loss , 'b', label='validation loss')
plt.title('Training and Validation  Loss')
plt.ylabel('loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()